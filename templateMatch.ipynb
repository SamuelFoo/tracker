{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from natsort import natsorted\n",
    "import time\n",
    "import multiprocessing.pool\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "from main import (resize, getROIFromVideo, cropWithROI, getTemplatesFromVideo, \n",
    "                  SelectionWindow, CalibWindow, getTemplateMatches, getOutputVidFrameSize)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidPath = \"screw.mp4\"\n",
    "crop_roi = getROIFromVideo(vidPath)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidPath = \"screw.mp4\"\n",
    "vs = cv2.VideoCapture(vidPath)\n",
    "ret, frame = vs.read()\n",
    "frame = cropWithROI(frame, crop_roi)\n",
    "\n",
    "perspectiveWindow = SelectionWindow(\"Perspective\", frame)\n",
    "perspectiveWindow.displayWindow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspectiveWindow.selectionPts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objLength = 1.83\n",
    "objWidth = 0.6\n",
    "imgWidth = 200\n",
    "imgHeight = round(objLength/objWidth*imgWidth)\n",
    "\n",
    "srcPts = np.float32(perspectiveWindow.selectionPts)\n",
    "dstPts = np.float32([(0, 0), (imgWidth, 0), (imgWidth, imgHeight), (0, imgHeight)])\n",
    "M = cv2.getPerspectiveTransform(srcPts, dstPts)\n",
    "dst = cv2.warpPerspective(frame, M, (imgWidth,imgHeight))\n",
    "cv2.imshow(\"Transformed\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(dst, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Template(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = lambda frame: cv2.warpPerspective(cropWithROI(frame, crop_roi), M, (imgWidth, imgHeight))\n",
    "pipeline = lambda frame: cropWithROI(frame, crop_roi)\n",
    "templates = getTemplatesFromVideo(vidPath, pipeline, templateWidth=100, templateHeight=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Template(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templatesDir = Path(\"templates_screw\")\n",
    "imgPaths = natsorted([str(path) for path in templatesDir.glob(\"*.jpg\")])\n",
    "\n",
    "if imgPaths:\n",
    "    latestImgN = int(Path(imgPaths[-1]).stem)+1\n",
    "else:\n",
    "    latestImgN = 0\n",
    "    \n",
    "for i in range(len(templates)):\n",
    "    cv2.imwrite(str(templatesDir/f\"{latestImgN+i}.jpg\"), templates[i])\n",
    "\n",
    "templates.clear()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Template(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templatesDir = Path(\"templates_screw\")\n",
    "imgPaths = templatesDir.glob(\"*.jpg\")\n",
    "\n",
    "templates = []\n",
    "for imgPath in imgPaths:\n",
    "    template = cv2.imread(str(imgPath))\n",
    "    templates.append(template)\n",
    "    cv2.imshow(\"Template\", template)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VID_PATH = \"screw.mp4\"\n",
    "OUTPUT_VID_PATH = \"screw_output.mp4\"\n",
    "OUTPUT_HEIGHT = 800\n",
    "\n",
    "NMS_THRESHOLD = 0.7\n",
    "CONFIDENCE_THRESHOLD = 0.8\n",
    "\n",
    "IMSHOW_FLAG = True\n",
    "WRITE_FLAG = True\n",
    "\n",
    "num_cpu = multiprocessing.cpu_count() - 1\n",
    "pool = multiprocessing.pool.ThreadPool(processes=num_cpu)\n",
    "\n",
    "cap = cv2.VideoCapture(VID_PATH)\n",
    "\n",
    "totalFrames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "frameCount = 0\n",
    "startTime = time.time()\n",
    "\n",
    "pipeline = lambda frame: cropWithROI(frame, crop_roi)\n",
    "# pipeline = lambda frame: cv2.warpPerspective(cropWithROI(frame, crop_roi), M, (imgWidth, imgHeight))\n",
    "\n",
    "frameWidth, frameHeight = getOutputVidFrameSize(VID_PATH, pipeline, OUTPUT_HEIGHT)\n",
    "out = cv2.VideoWriter(OUTPUT_VID_PATH, cv2.VideoWriter_fourcc(*\"mp4v\"), cap.get(cv2.CAP_PROP_FPS), (frameWidth,frameHeight))\n",
    "print(f\"Output frame width: {frameWidth}, frame height: {frameHeight}\")\n",
    "\n",
    "saveFrames = []\n",
    "saveBoxes = []\n",
    "\n",
    "ret, frame = cap.read()\n",
    "while ret: \n",
    "    if frameCount % 100 == 0 and frameCount != 0:\n",
    "        elapsedTime = time.time()-startTime\n",
    "        estTimeLeft = (totalFrames-frameCount)/frameCount*elapsedTime\n",
    "        print(f\"Frame {frameCount} out of {round(totalFrames)}.\")\n",
    "        print(f\"\\tTime taken: {round(elapsedTime)}s. Est. time left: {round(estTimeLeft)}s\")\n",
    "\n",
    "    img_rgb = pipeline(frame)\n",
    "\n",
    "    # Multithreading\n",
    "    mapIterable = []\n",
    "    for i in range(len(templates)):\n",
    "        template = templates[i]\n",
    "        mapIterable.append((img_rgb, template, CONFIDENCE_THRESHOLD))\n",
    "    results = pool.starmap(func=getTemplateMatches, iterable=mapIterable)\n",
    "\n",
    "    boxes, confidences = [], []\n",
    "    for result in results:\n",
    "        boxes.extend(result[0])\n",
    "        confidences.extend(result[1])\n",
    "\n",
    "    # Serial\n",
    "    # boxes, confidences = [], []\n",
    "    # for template in templates:\n",
    "    #     val = getTemplateMatches(img_rgb, template, CONFIDENCE_THRESHOLD)\n",
    "    #     boxes.extend(val[0])\n",
    "    #     confidences.extend(val[1])\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, CONFIDENCE_THRESHOLD, NMS_THRESHOLD)\n",
    "    boxes = [boxes[idx] for idx in indices]\n",
    "    confidences = [confidences[idx] for idx in indices]\n",
    "    \n",
    "    if boxes:\n",
    "        saveFrames.append(frameCount)\n",
    "        saveBoxes.append(boxes[0].copy())\n",
    "\n",
    "    for box in boxes:\n",
    "        cv2.rectangle(img_rgb, box[:2], box[2:], (0,0,255), 2)\n",
    "    \n",
    "    img_rgb = imutils.resize(img_rgb, height=OUTPUT_HEIGHT)\n",
    "\n",
    "    if WRITE_FLAG:\n",
    "        out.write(img_rgb)\n",
    "\n",
    "    if IMSHOW_FLAG:\n",
    "        cv2.imshow(\"Detections\", img_rgb)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q') or key == ord('Q'):\n",
    "            break\n",
    " \n",
    "    ret, frame = cap.read()\n",
    "    frameCount += 1\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "out.release()\n",
    "cap.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multithreading Time (1100 frames, 5 threads, 5 templates): 75s  \n",
    "Serial Time (1100 frames, 5 templates): 193s\n",
    "\n",
    "TODO: try with map_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# f = open(\"temp.pkl\", \"wb\")\n",
    "# pickle.dump([saveFrames, saveBoxes], f)\n",
    "\n",
    "# f = open(\"temp.pkl\", \"rb\")\n",
    "# pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(VID_PATH)\n",
    "ret, frame = cap.read()\n",
    "\n",
    "img_rgb = pipeline(frame)\n",
    "\n",
    "# CalibWin = CalibWindow(\"Calibration\", img_rgb)\n",
    "# CalibWin.displayWindow()\n",
    "# calibPoints = CalibWin.calibPoints\n",
    "# calibLength = 0.60\n",
    "# scale = CalibWin.getCalibScale(calibLength)\n",
    "# key = cv2.waitKey(0)\n",
    "\n",
    "scale = img_rgb.shape[1]/objWidth\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = np.array([[(b[0]+b[2])/2, (b[1]+b[3])/2] for b in saveBoxes])/scale\n",
    "plt.scatter(saveFrames[::1], coords[:,1][::1], s=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvPath = Path(VID_PATH).stem + \".csv\"\n",
    "df = pd.DataFrame([saveFrames, coords[:,0], coords[:,1]]).T\n",
    "df.to_csv(csvPath, index=None, header=[\"frame\",\"x\",\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(VID_PATH)\n",
    "h = int(cap.get(cv2.CAP_PROP_FOURCC))\n",
    "codec = chr(h&0xff) + chr((h>>8)&0xff) + chr((h>>16)&0xff) + chr((h>>24)&0xff)\n",
    "codec\n",
    "\n",
    "cap.get(cv2.CAP_PROP_FPS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Junk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"video.mov\")\n",
    "ret, frame = cap.read()\n",
    "while ret:    \n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    frame = frame[int(roi[1]):int(roi[1]+roi[3]), int(roi[0]):int(roi[0]+roi[2])]\n",
    "\n",
    "    cv2.imshow(\"RGB\", frame)\n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    cv2.imshow(\"HSV\", hsv)\n",
    "    h,s,v = cv2.split(hsv)\n",
    "\n",
    "    ret, th = cv2.threshold(v, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "    cv2.imshow(\"OTSU\", th)\n",
    "    cv2.imshow(\"V\", v)\n",
    "\n",
    "    rows = v.shape[0]\n",
    "    circles = cv2.HoughCircles(v, cv2.HOUGH_GRADIENT_ALT, 1, rows/128,\n",
    "                               param1=500, param2=0.8,\n",
    "                               minRadius=1, maxRadius=200)\n",
    "    \n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        for i in circles[0, :]:\n",
    "            center = (i[0], i[1])\n",
    "            # circle center\n",
    "            cv2.circle(frame, center, 1, (0, 100, 100), 1)\n",
    "            # circle outline\n",
    "            radius = i[2]\n",
    "            cv2.circle(frame, center, radius, (255, 0, 255), 1)\n",
    "    \n",
    "    cv2.imshow(\"detected circles\", frame)\n",
    "    key = cv2.waitKey(0)\n",
    "\n",
    "    if key == ord('q') or key == ord('Q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysift\n",
    "sift = cv2.SIFT_create()\n",
    "def getTemplateMatchesSIFT(frame, template, confidenceThresh):\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp1, des1 = sift.detectAndCompute(frame, None)\n",
    "    kp2, des2 = sift.detectAndCompute(template, None)\n",
    "\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=20)\n",
    "    search_params = dict(checks=150)\n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    # find matches by knn which calculates point distance in 128 dim\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    good_matches = [[0, 0] for i in range(len(matches))]\n",
    "    for i, (m, n) in enumerate(matches):\n",
    "        if m.distance < confidenceThresh*n.distance:\n",
    "            good.append(m)\n",
    "            good_matches[i] = [1, 0]    \n",
    "\n",
    "    Matched = cv2.drawMatchesKnn(frame,\n",
    "                             kp1,\n",
    "                             template,\n",
    "                             kp2,\n",
    "                             matches,\n",
    "                             outImg=None,\n",
    "                             matchColor=(0, 155, 0),\n",
    "                             singlePointColor=(0, 255, 255),\n",
    "                             matchesMask=good_matches,\n",
    "                             flags=0\n",
    "                             )\n",
    "\n",
    "    return good, Matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vidPath = \"screw.mp4\"\n",
    "cap = cv2.VideoCapture(vidPath)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 100)\n",
    "res, frame = cap.read()\n",
    "\n",
    "cv2.imshow(\"frame\", templates[0])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "template = templates[3]\n",
    "vidPath = \"screw.mp4\"\n",
    "cap = cv2.VideoCapture(vidPath)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 100)\n",
    "res, frame = cap.read()\n",
    "\n",
    "# frame = cv2.imread(\"geeks-full.png\")\n",
    "# template = cv2.imread(\"geeks-half.jpg\")\n",
    "\n",
    "good, matched = getTemplateMatchesSIFT(frame, template, 0.5)\n",
    "cv2.imshow(\"test\", matched)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
