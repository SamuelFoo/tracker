{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imutils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from main import (getROIFromVideo, cropWithROI, getOutputVidFrameSize, CalibWindow, \n",
    "                  getFrameFromVid, SelectionWindow, showImg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidPath = Path(\"data/screw/screw.mp4\")\n",
    "crop_roi = getROIFromVideo(str(vidPath))\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# f = open(\"temp_crop.pkl\", \"wb\")\n",
    "# pickle.dump(crop_roi, f)\n",
    "\n",
    "# f = open(\"temp.pkl\", \"rb\")\n",
    "# pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VID_PATH = Path(\"data/screw/C0003.mp4\")\n",
    "vs = cv2.VideoCapture(str(VID_PATH))\n",
    "ret, frame = vs.read()\n",
    "\n",
    "perspectiveWindow = SelectionWindow(\"Perspective\", frame)\n",
    "perspectiveWindow.displayWindow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objLength = 1.83\n",
    "objWidth = 0.6\n",
    "imgWidth = 200\n",
    "imgHeight = round(objLength/objWidth*imgWidth)\n",
    "\n",
    "srcPts = np.float32(perspectiveWindow.selectionPts)\n",
    "dstPts = np.float32([(0, 0), (imgWidth, 0), (imgWidth, imgHeight), (0, imgHeight)])\n",
    "M = cv2.getPerspectiveTransform(srcPts, dstPts)\n",
    "dst = cv2.warpPerspective(frame, M, (imgWidth,imgHeight))\n",
    "\n",
    "plt.imshow(cv2.cvtColor(dst, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 100 out of 192.\n",
      "\tTime taken: 20s. Est. time left: 18s\n"
     ]
    }
   ],
   "source": [
    "VID_PATH = Path(\"data/pancake/IMG_2902.mp4\")\n",
    "OUTPUT_VID_PATH = VID_PATH.parent/(VID_PATH.stem+\"_output.mp4\")\n",
    "OUTPUT_HEIGHT = 800\n",
    "pipeline = lambda frame: frame\n",
    "# pipeline = lambda frame: cv2.warpPerspective(frame, M, (imgWidth, imgHeight)) \n",
    "# pipeline = lambda frame: cropWithROI(frame, crop_roi)\n",
    "\n",
    "IMSHOW_FLAG = True\n",
    "WRITE_FLAG = True\n",
    "\n",
    "cap = cv2.VideoCapture(str(VID_PATH))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "frameWidth, frameHeight = getOutputVidFrameSize(str(VID_PATH), pipeline, OUTPUT_HEIGHT)\n",
    "out = cv2.VideoWriter(str(OUTPUT_VID_PATH), cv2.VideoWriter_fourcc(*\"mp4v\"), cap.get(cv2.CAP_PROP_FPS), (frameWidth,frameHeight))\n",
    "\n",
    "totalFrames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "frameCount = 0\n",
    "startTime = time.time()\n",
    "saveFrames = []\n",
    "saveCnts = []\n",
    "centroids = []\n",
    "\n",
    "ret, frame = cap.read()\n",
    "while ret:\n",
    "    if frameCount % 100 == 0 and frameCount != 0:\n",
    "        elapsedTime = time.time()-startTime\n",
    "        estTimeLeft = (totalFrames-frameCount)/frameCount*elapsedTime\n",
    "        print(f\"Frame {frameCount} out of {round(totalFrames)}.\")\n",
    "        print(f\"\\tTime taken: {round(elapsedTime)}s. Est. time left: {round(estTimeLeft)}s\")\n",
    "\n",
    "    frame = pipeline(frame)\n",
    "    frame_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    (frame_h,frame_s,frame_v) = cv2.split(frame_hsv)\n",
    "\n",
    "    # ret, th = cv2.threshold(frame_h, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    th = cv2.inRange(frame_h, 90, 120) & cv2.inRange(frame_s, 120, 255)\n",
    "    cnts, hierarchy = cv2.findContours(th, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n",
    "\n",
    "    if cnts:\n",
    "        cnt = max(cnts, key=cv2.contourArea)\n",
    "        M = cv2.moments(cnt)\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        centroids.append((cX, cY))\n",
    "        maxPts = 200\n",
    "        dAlpha = 1/100\n",
    "        firstPt = max(len(centroids)-maxPts, 0)\n",
    "        alpha = max(maxPts-len(centroids), 0)*dAlpha\n",
    "        for centroid in centroids[firstPt:]:\n",
    "            frameCopy = frame.copy()\n",
    "            cv2.circle(frameCopy, centroid, 5, (255,0,0), -1)\n",
    "            frame = cv2.addWeighted(frame, 1-alpha, frameCopy, alpha, 0)\n",
    "            alpha += dAlpha\n",
    "        # cv2.drawContours(frame, [cnt], -1, (255, 0, 0), 1)\n",
    "        saveFrames.append(frameCount)\n",
    "        saveCnts.append(cnt)\n",
    "\n",
    "    pts = np.array(centroids).reshape((-1, 1, 2))\n",
    "    frame = cv2.polylines(frame, [pts],\n",
    "                      False, (255,0,0), 5)\n",
    "\n",
    "    \n",
    "    frame = imutils.resize(frame, height=OUTPUT_HEIGHT)\n",
    "\n",
    "    if WRITE_FLAG:\n",
    "        out.write(frame)\n",
    "\n",
    "    if IMSHOW_FLAG:\n",
    "        cv2.imshow(\"Hue\", frame_h)\n",
    "        cv2.imshow(\"Saturation\", frame_s)\n",
    "        cv2.imshow(\"Value\", frame_v)\n",
    "        cv2.imshow(\"Detections\", frame)\n",
    "        key = cv2.waitKey(1)\n",
    "\n",
    "        if key == ord('q') or key == ord('Q'):\n",
    "            break\n",
    "\n",
    "        if key == ord('p') or key == ord('P'):\n",
    "            key = cv2.waitKey(0)\n",
    "            if key == ord('p') or key == ord('P'): \n",
    "                continue\n",
    "            \n",
    "    ret, frame = cap.read()\n",
    "    frameCount += 1\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "out.release()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# f = open(\"temp_track.pkl\", \"wb\")\n",
    "# pickle.dump([saveFrames, saveCnts], f)\n",
    "\n",
    "# f = open(\"temp.pkl\", \"rb\")\n",
    "# pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Calibration Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VID_PATH = Path(\"data/screw/C0003.MP4\")\n",
    "pipeline = lambda frame: cropWithROI(frame, crop_roi)\n",
    "\n",
    "frame = getFrameFromVid(str(VID_PATH), 1)\n",
    "img_rgb = pipeline(frame)\n",
    "calibLength = 1\n",
    "\n",
    "CalibWin = CalibWindow(\"Calibration\", img_rgb)\n",
    "CalibWin.displayWindow()\n",
    "calibPoints = CalibWin.calibPoints\n",
    "scale = CalibWin.getCalibScale(calibLength)\n",
    "key = cv2.waitKey(0)\n",
    "print(f\"Scale is {scale} pixels per metre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VID_PATH = Path(\"data/screw/C0003.MP4\")\n",
    "pipeline = lambda frame: cv2.warpPerspective(frame, M, (imgWidth, imgHeight)) \n",
    "frame = getFrameFromVid(str(VID_PATH), 1)\n",
    "img_rgb = pipeline(frame)\n",
    "\n",
    "objLength = 1.83\n",
    "objWidth = 0.6\n",
    "\n",
    "scale = img_rgb.shape[0]/objLength\n",
    "print(f\"Scale is {scale} pixels per metre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, xs, ys, ellipses = [], [], [], []\n",
    "\n",
    "VID_PATH = Path(\"data/screw/C0003.MP4\")\n",
    "pipeline = lambda frame: cv2.warpPerspective(frame, M, (imgWidth, imgHeight)) \n",
    "frame = getFrameFromVid(str(VID_PATH), 1)\n",
    "img_rgb = pipeline(frame)\n",
    "rows,cols = img_rgb.shape[:2]\n",
    "\n",
    "for frame, c in zip(saveFrames, saveCnts):\n",
    "    moments = cv2.moments(c)\n",
    "    if moments[\"m00\"] > 0 and len(c) >= 5:\n",
    "        xs.append(moments[\"m10\"] / moments[\"m00\"])\n",
    "        ys.append(moments[\"m01\"] / moments[\"m00\"])\n",
    "        frames.append(frame)\n",
    "        \n",
    "        ellipse = cv2.fitEllipse(c)\n",
    "        # gradient = vy[0]/vx[0]\n",
    "        ellipses.append(ellipse)\n",
    "\n",
    "frames = np.array(frames)     \n",
    "xs = np.array(xs)/scale\n",
    "ys = np.array(ys)/scale\n",
    "\n",
    "mask = (frames > 875) & (frames < 1375)\n",
    "\n",
    "plt.plot(frames[mask], xs[mask])\n",
    "plt.plot(frames[mask], ys[mask])\n",
    "plt.show()\n",
    "angles = np.array([e[2]-180 if e[2] > 90 else e[2] for e in ellipses])\n",
    "plt.plot(frames[mask], angles[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvPath = Path(VID_PATH).parent / (Path(VID_PATH).stem + \".csv\")\n",
    "df = pd.DataFrame([saveFrames, xs, ys, angles]).T\n",
    "df.to_csv(csvPath, index=None, header=[\"frame\",\"x\",\"y\",\"angle\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Calibration Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if getCalib: # Assume camera does not move between videos\n",
    "#     # Set calibration length\n",
    "#     CalibWin = CircleCalibWindow(\"Calibration\", frame_trunc)\n",
    "#     CalibWin.displayWindow()\n",
    "#     scale = CalibWin.getCalibScale(calibRadius)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path(\"data/pancake/\")\n",
    "FILE_PATH = cwd/\"IMG_2904.csv\"\n",
    "df = pd.read_csv(FILE_PATH, delimiter=\"\\t\", header=None)\n",
    "df.columns = [\"t\", \"x\", \"y\"]\n",
    "x = df[\"x\"]\n",
    "y = df[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 100 out of 326.\n",
      "\tTime taken: 2s. Est. time left: 4s\n",
      "Frame 200 out of 326.\n",
      "\tTime taken: 4s. Est. time left: 2s\n",
      "Frame 300 out of 326.\n",
      "\tTime taken: 5s. Est. time left: 0s\n"
     ]
    }
   ],
   "source": [
    "VID_PATH = cwd/\"IMG_2904.mp4\"\n",
    "OUTPUT_VID_PATH = VID_PATH.parent/(VID_PATH.stem+\"_output.mp4\")\n",
    "OUTPUT_HEIGHT = 800\n",
    "pipeline = lambda frame: frame\n",
    "# pipeline = lambda frame: cv2.warpPerspective(frame, M, (imgWidth, imgHeight)) \n",
    "# pipeline = lambda frame: cropWithROI(frame, crop_roi)\n",
    "\n",
    "IMSHOW_FLAG = True\n",
    "WRITE_FLAG = True\n",
    "\n",
    "maxPts = 200\n",
    "dAlpha = 1/100\n",
    "alpha = 0.5\n",
    "\n",
    "cap = cv2.VideoCapture(str(VID_PATH))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "frameWidth, frameHeight = getOutputVidFrameSize(str(VID_PATH), pipeline, OUTPUT_HEIGHT)\n",
    "out = cv2.VideoWriter(str(OUTPUT_VID_PATH), cv2.VideoWriter_fourcc(*\"mp4v\"), cap.get(cv2.CAP_PROP_FPS), (frameWidth,frameHeight))\n",
    "\n",
    "totalFrames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "frameCount = 0\n",
    "startTime = time.time()\n",
    "centroids = []\n",
    "\n",
    "startFrameCount = 1\n",
    "\n",
    "ret, frame = cap.read()\n",
    "cols, rows, _ = frame.shape\n",
    "while ret:\n",
    "    if frameCount % 100 == 0 and frameCount != 0:\n",
    "        elapsedTime = time.time()-startTime\n",
    "        estTimeLeft = (totalFrames-frameCount)/frameCount*elapsedTime\n",
    "        print(f\"Frame {frameCount} out of {round(totalFrames)}.\")\n",
    "        print(f\"\\tTime taken: {round(elapsedTime)}s. Est. time left: {round(estTimeLeft)}s\")\n",
    "\n",
    "    if frameCount < startFrameCount:\n",
    "        ret, frame = cap.read()\n",
    "        frameCount += 1\n",
    "\n",
    "    frame = pipeline(frame)\n",
    "\n",
    "    if frameCount < len(x):\n",
    "        centroids.append((int(x[frameCount]+rows//2), int(cols//2-y[frameCount])))\n",
    "\n",
    "    frameCopy = frame.copy()\n",
    "\n",
    "    pts = np.array(centroids).reshape((-1, 1, 2))\n",
    "    frame = cv2.polylines(frame, [pts],\n",
    "                      False, (255,0,0), 5)\n",
    "\n",
    "    frame = cv2.addWeighted(frame, 1-alpha, frameCopy, alpha, 0)\n",
    "\n",
    "    # firstPt = max(len(centroids)-maxPts, 0)\n",
    "    # alpha = max(maxPts-len(centroids), 0)*dAlpha\n",
    "    # for centroid in centroids[firstPt:]:\n",
    "    #     frameCopy = frame.copy()\n",
    "    #     cv2.circle(frameCopy, centroid, 5, (255,0,0), -1)\n",
    "    #     frame = cv2.addWeighted(frame, 1-alpha, frameCopy, alpha, 0)\n",
    "    #     alpha += dAlpha\n",
    "\n",
    "    # cv2.drawContours(frame, [cnt], -1, (255, 0, 0), 1)\n",
    "    \n",
    "    frame = imutils.resize(frame, height=OUTPUT_HEIGHT)\n",
    "\n",
    "    if WRITE_FLAG:\n",
    "        out.write(frame)\n",
    "\n",
    "    if IMSHOW_FLAG:\n",
    "        cv2.imshow(\"Detections\", frame)\n",
    "        key = cv2.waitKey(1)\n",
    "\n",
    "        if key == ord('q') or key == ord('Q'):\n",
    "            break\n",
    "\n",
    "        if key == ord('p') or key == ord('P'):\n",
    "            key = cv2.waitKey(0)\n",
    "            if key == ord('p') or key == ord('P'): \n",
    "                continue\n",
    "            \n",
    "    ret, frame = cap.read()\n",
    "    frameCount += 1\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "out.release()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frameCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import image\n",
    "imgPath = Path(\"Image5.tif\")\n",
    "img = cv2.imread(str(imgPath))\n",
    "\n",
    "# Crop\n",
    "r = cv2.selectROI(img, fromCenter=False)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped = cropWithROI(img, r)\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)\n",
    "# gray = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "# Iteratively increase contrast\n",
    "iterations = 12\n",
    "clahe = cv2.createCLAHE(clipLimit=1.1, tileGridSize=(12,12))\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (18, 18))\n",
    "tophat1 = gray.copy()\n",
    "for i in range(iterations):\n",
    "    cl1 = clahe.apply(tophat1)\n",
    "    tophat1 = cv2.morphologyEx(cl1, cv2.MORPH_TOPHAT, cl1)\n",
    "\n",
    "\n",
    "cv2.imwrite(\"gel_electrophoresis_enhanced.jpg\", tophat1)\n",
    "showImg(tophat1)\n",
    "\n",
    "# # Morph to strips\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 1))\n",
    "tophat1 = cv2.morphologyEx(tophat1, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imwrite(\"gel_electrophoresis_enhanced2.jpg\", tophat1)\n",
    "\n",
    "showImg(tophat1)\n",
    "\n",
    "# Threshold\n",
    "# tophat1 = cv2.GaussianBlur(tophat1, (5,5), 0)\n",
    "ret, th = cv2.threshold(tophat1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Display\n",
    "showImg(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnts, _ = cv2.findContours(tophat1, cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "cv2.drawContours(cropped, cnts, -1, (0,0,255), 1)\n",
    "showImg(cropped)\n",
    "\n",
    "# th3 = cv2.adaptiveThreshold(tophat1,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,4)\n",
    "# cv2.imshow(\"display\", th3)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "th3 = cv2.adaptiveThreshold(cl1,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,4)\n",
    "cv2.imshow(\"display\", th3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tracker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
